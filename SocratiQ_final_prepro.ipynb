{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Final preprocessing of full data set for 4 question types (! STRONG threshold here!)",
   "id": "41bab268dcf9f851"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### lentgh filtering",
   "id": "57507ae3d4b612b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T16:21:21.462319Z",
     "start_time": "2025-05-15T16:15:25.899142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "nltk.download('framenet_v17')\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"Data/processed/SocratiQ/train_chunk_I.csv\",\n",
    "    names=[\"category\", \"context\", \"question\"]\n",
    ")\n",
    "\n",
    "df[\"context_token_len\"] = df[\"context\"].apply(lambda text: len(nlp(text)))\n",
    "filtered_df = df[df[\"context_token_len\"] >= 25].copy()\n",
    "\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Rows after filtering: {len(filtered_df)}\")"
   ],
   "id": "488634547f88d664",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenaraichle/Developer/NLP-project_v1/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package framenet_v17 to\n",
      "[nltk_data]     /Users/lorenaraichle/nltk_data...\n",
      "[nltk_data]   Package framenet_v17 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 28195\n",
      "Rows after filtering: 26804\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. cause to effect",
   "id": "d3dbe6be2d9c3d07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T16:24:05.012524Z",
     "start_time": "2025-05-15T16:24:05.003862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.corpus import framenet as fn\n",
    "\n",
    "def get_causal_verbs_from_framenet():\n",
    "    causal_frame_names = [\n",
    "        \"Causation\", \"Cause_change\", \"Cause_change_of_position_on_a_scale\",\n",
    "        \"Cause_motion\", \"Cause_to_amalgamate\", \"Cause_to_start\", \"Cause_to_make_progress\"\n",
    "    ]\n",
    "\n",
    "    causal_verbs = set()\n",
    "    for frame_name in causal_frame_names:\n",
    "        try:\n",
    "            frame = fn.frame_by_name(frame_name)\n",
    "            for lu in frame.lexUnit.values():\n",
    "                if '.v' in lu['name']:  # Only verbs\n",
    "                    causal_verbs.add(lu['name'].split('.')[0])\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading frame '{frame_name}': {e}\")\n",
    "    \n",
    "    return causal_verbs\n",
    "\n",
    "\n",
    "\n",
    "def detect_cause_to_effect(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    explanations = []\n",
    "    score = 0\n",
    "\n",
    "    causal_verbs = get_causal_verbs_from_framenet()\n",
    "\n",
    "    has_condition = any(tok.dep_ == \"mark\" and tok.text.lower() in {\"if\", \"when\"} for tok in doc)\n",
    "    if has_condition:\n",
    "        explanations.append(\"✓ Conditional clause detected (e.g., 'if', 'when')\")\n",
    "        score += 2\n",
    "\n",
    "    has_advcl = any(tok.dep_ == \"advcl\" for tok in doc)\n",
    "    if has_advcl:\n",
    "        explanations.append(\"✓ Adverbial clause (likely effect clause) detected\")\n",
    "        score += 2\n",
    "\n",
    "    has_causal_verb_structure = False\n",
    "    for tok in doc:\n",
    "        if tok.lemma_ in causal_verbs and tok.pos_ == \"VERB\":\n",
    "            subj = any(child.dep_ == \"nsubj\" for child in tok.children)\n",
    "            obj = any(child.dep_ == \"dobj\" for child in tok.children)\n",
    "            prep = any(child.dep_ == \"prep\" for child in tok.children)\n",
    "            if subj or obj or prep:\n",
    "                has_causal_verb_structure = True\n",
    "                explanations.append(\n",
    "                    f\"✓ Verb '{tok.lemma_}' is listed in FrameNet under causal frames with subject/object/prep\"\n",
    "                )\n",
    "                score += 2\n",
    "                if subj: score += 1\n",
    "                if obj: score += 1\n",
    "                if prep: score += 1\n",
    "                break\n",
    "\n",
    "    is_causal = has_condition and has_advcl or has_causal_verb_structure\n",
    "    if not is_causal:\n",
    "        causal_phrases = [\"result in\", \"lead to\", \"cause\", \"because of\", \"due to\"]\n",
    "        if any(phrase in sentence.lower() for phrase in causal_phrases):\n",
    "            explanations.append(\"✓ Phrase pattern matches known cause-to-effect trigger\")\n",
    "            score += 1\n",
    "\n",
    "    score = min(score, 10)\n",
    "    label = \"Strong CauseToEffect\" if score >= 7 else \"Weak/Partial CauseToEffect\" if score >= 4 else \"Not CauseToEffect\"\n",
    "    return label, score, explanations\n"
   ],
   "id": "abaa90b8f8570b7a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. expert opinion",
   "id": "643fcb1c1bf9051d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T16:24:07.108589Z",
     "start_time": "2025-05-15T16:24:06.511692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_lexical_units_from_frames(frames):\n",
    "    terms = set()\n",
    "    for frame_name in frames:\n",
    "        try:\n",
    "            frame = fn.frame_by_name(frame_name)\n",
    "            for lu in frame.lexUnit.values():\n",
    "                if '.v' in lu['name']:\n",
    "                    terms.add(lu['name'].split('.')[0])\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not load frame '{frame_name}': {e}\")\n",
    "    return terms\n",
    "\n",
    "\n",
    "expert_frames = [\n",
    "    \"Expertise\", \"Judgment_communication\", \"Opinion\",\n",
    "    \"Authority\", \"Statement\", \"Certainty\"\n",
    "]\n",
    "quote_frames = [\"Statement\", \"Judgment_communication\"]\n",
    "clarity_frames = [\"Reasoning\"]\n",
    "evidence_frames = [\"Evidence\", \"Certainty\", \"Causation\"]\n",
    "\n",
    "\n",
    "expert_verbs = get_lexical_units_from_frames(expert_frames)\n",
    "quote_verbs = get_lexical_units_from_frames(quote_frames)\n",
    "clarity_terms = get_lexical_units_from_frames(clarity_frames)\n",
    "evidence_terms = get_lexical_units_from_frames(evidence_frames)\n",
    "\n",
    "def detect_expert_opinion(question):\n",
    "    \n",
    "    doc = nlp(question)\n",
    "    score = 0\n",
    "    explanations = []\n",
    "\n",
    "    expert_titles = {\"expert\", \"researcher\", \"scientist\", \"doctor\", \"analyst\", \"professor\", \"Dr.\"}\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in {\"PERSON\", \"ORG\"}:\n",
    "            if any(title in ent.text.lower() for title in expert_titles):\n",
    "                explanations.append(f\"✓ Expert entity detected: '{ent.text}'\")\n",
    "                score += 2\n",
    "                break\n",
    "\n",
    "    if any(tok.lemma_ in expert_verbs for tok in doc if tok.pos_ == \"VERB\"):\n",
    "        explanations.append(\"✓ Detected expert-related verb from FrameNet\")\n",
    "        score += 2\n",
    "\n",
    "    if any(tok.lemma_ in quote_verbs for tok in doc):\n",
    "        explanations.append(\"✓ Quotation or claim verb found\")\n",
    "        score += 1\n",
    "\n",
    "    if any(tok.lemma_ in clarity_terms for tok in doc):\n",
    "        explanations.append(\"✓ Clarity/definition markers found\")\n",
    "        score += 1\n",
    "\n",
    "    if any(tok.lemma_ in evidence_terms for tok in doc):\n",
    "        explanations.append(\"✓ Evidence or support-related terms found\")\n",
    "        score += 2\n",
    "\n",
    "    label = \"Strong Expert Opinion\" if score >= 6 else \"Weak/Partial Expert Opinion\" if score >= 3 else \"Not Expert Opinion\"\n",
    "    return label, score, explanations\n"
   ],
   "id": "4b793c6ec8764e49",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Analogy detection",
   "id": "755d0a67225dbe50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T16:24:09.963923Z",
     "start_time": "2025-05-15T16:24:08.288629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "analogy_synsets = [wn.synset('similar.a.01'), wn.synset('analogy.n.01'), wn.synset('compare.v.01')]\n",
    "\n",
    "comparison_frames = [\"Similarity\"]\n",
    "contrast_frames = [\"Categorization\"]\n",
    "evidence_frames = [\"Evidence\", \"Judgment_communication\"]\n",
    "\n",
    "comparison_verbs = get_lexical_units_from_frames(comparison_frames)\n",
    "contrast_verbs = get_lexical_units_from_frames(contrast_frames)\n",
    "evidence_verbs = get_lexical_units_from_frames(evidence_frames)\n",
    "\n",
    "def is_semantically_analogical(token):\n",
    "    token_synsets = wn.synsets(token.lemma_)\n",
    "    for s in token_synsets:\n",
    "        for analogy_syn in analogy_synsets:\n",
    "            if s.path_similarity(analogy_syn) and s.path_similarity(analogy_syn) > 0.3:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def detect_analogy_question(question):\n",
    "    doc = nlp(question)\n",
    "    score = 0\n",
    "    explanations = []\n",
    "    noun_chunks = list(doc.noun_chunks)\n",
    "\n",
    "    if any(tok.lemma_ in comparison_verbs for tok in doc if tok.pos_ == \"VERB\"):\n",
    "        explanations.append(\"✓ Comparison verb detected from FrameNet\")\n",
    "        score += 2\n",
    "\n",
    "    entity_tokens = [tok for tok in doc if tok.pos_ in {\"PROPN\", \"NOUN\"}]\n",
    "    if len(set(tok.lemma_ for tok in entity_tokens)) >= 2:\n",
    "        explanations.append(\"✓ Contains at least two distinct concepts/entities\")\n",
    "        score += 1\n",
    "\n",
    "    if any(tok.lemma_ in contrast_verbs for tok in doc if tok.pos_ == \"VERB\"):\n",
    "        explanations.append(\"✓ Contrast or difference verb detected from FrameNet\")\n",
    "        score += 1\n",
    "\n",
    "    if any(tok.lemma_ in evidence_verbs for tok in doc if tok.pos_ == \"VERB\"):\n",
    "        explanations.append(\"✓ Evidence or justification verb found\")\n",
    "        score += 1\n",
    "\n",
    "    if any(tok.tag_ == \"MD\" for tok in doc):\n",
    "        score += 1\n",
    "\n",
    "    if len(noun_chunks) >= 2 and any(tok.lemma_ in {\"similar\", \"like\", \"as\"} for tok in doc):\n",
    "        explanations.append(\"✓ Two concepts compared with similarity cue (e.g., 'similar', 'like')\")\n",
    "        score += 2\n",
    "\n",
    "    if any(tok.text.lower() == \"if\" for tok in doc):\n",
    "        explanations.append(\"✓ Conditional structure suggesting hypothetical reasoning\")\n",
    "        score += 1\n",
    "\n",
    "    if any(is_semantically_analogical(tok) for tok in doc if tok.pos_ in {\"ADJ\", \"NOUN\", \"VERB\"}):\n",
    "        explanations.append(\"✓ Semantic similarity to analogy-related terms detected via WordNet\")\n",
    "        score += 2\n",
    "\n",
    "    if any(tok.dep_ in {\"prep\", \"relcl\"} and tok.lemma_ in {\"compare\", \"similar\"} for tok in doc):\n",
    "        explanations.append(\"✓ Syntactic cue of analogy (e.g., 'compared with', 'similar to')\")\n",
    "        score += 1\n",
    "\n",
    "    label = \"Strong Analogy Question\" if score >= 8 else \"Weak/Partial Analogy Question\" if score >= 5 else \"Not Analogy Question\"\n",
    "    return label, score, explanations\n"
   ],
   "id": "42e76e57e97bbaba",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. Bias",
   "id": "a2cf149cfa5caa03"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T16:24:11.581068Z",
     "start_time": "2025-05-15T16:24:11.567985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def is_fear_related(token):\n",
    "    syns = wn.synsets(token.lemma_)\n",
    "    for s in syns:\n",
    "        if any(s.path_similarity(wn.synset('danger.n.01')) or\n",
    "               s.path_similarity(wn.synset('fear.n.01')) or\n",
    "               s.path_similarity(wn.synset('threat.n.01')) for s in syns):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# ---- FrameNet Utility ----\n",
    "def get_lexical_units_from_frames(frames):\n",
    "    terms = set()\n",
    "    for frame_name in frames:\n",
    "        try:\n",
    "            frame = fn.frame_by_name(frame_name)\n",
    "            for lu in frame.lexUnit.values():\n",
    "                if '.v' in lu['name']:\n",
    "                    terms.add(lu['name'].split('.')[0])\n",
    "        except:\n",
    "            continue\n",
    "    return terms\n",
    "\n",
    "# ---- Relevant Lexical Resources ----\n",
    "causal_frames = [\"Causation\", \"Cause_to_start\", \"Preventing\", \"Risk\", \"Threaten\", \"Danger\"]\n",
    "causal_verbs = get_lexical_units_from_frames(causal_frames)\n",
    "\n",
    "fear_keywords = {\"danger\", \"threat\", \"risky\", \"harm\", \"catastrophe\", \"crisis\", \"ruin\", \"fear\", \"worse\", \"bad\", \"fatal\"}\n",
    "preventive_keywords = {\"prevent\", \"avoid\", \"stop\", \"ban\", \"rescue\", \"save\", \"protect\"}\n",
    "modal_keywords = {\"might\", \"could\", \"would\", \"may\", \"should\"}\n",
    "\n",
    "def detect_fear_appeal_question(question):\n",
    "    doc = nlp(question)\n",
    "    score = 0\n",
    "    explanations = []\n",
    "\n",
    "    if any(tok.lemma_ in modal_keywords for tok in doc if tok.tag_ == \"MD\"):\n",
    "        explanations.append(\"✓ Modal verb detected (e.g., 'might', 'would') suggesting hypothetical risk\")\n",
    "        score += 1\n",
    "\n",
    "    if any(tok.lemma_.lower() in fear_keywords for tok in doc):\n",
    "        explanations.append(\"✓ Fear-related keyword detected (e.g., 'threat', 'danger')\")\n",
    "        score += 2\n",
    "\n",
    "    if any(tok.lemma_.lower() in preventive_keywords for tok in doc):\n",
    "        explanations.append(\"✓ Preventive action verb detected (e.g., 'prevent', 'stop')\")\n",
    "        score += 2\n",
    "\n",
    "    if any(tok.lemma_ in causal_verbs for tok in doc if tok.pos_ == \"VERB\"):\n",
    "        explanations.append(\"✓ Causal/preventive verb from FrameNet detected\")\n",
    "        score += 2\n",
    "\n",
    "    if any(tok.text.lower() in {\"if\", \"unless\"} for tok in doc):\n",
    "        explanations.append(\"✓ Conditional clause found (e.g., 'if', 'unless')\")\n",
    "        score += 1\n",
    "\n",
    "    if any(is_fear_related(tok) for tok in doc if tok.pos_ in {\"NOUN\", \"VERB\", \"ADJ\"}):\n",
    "        explanations.append(\"✓ Semantic fear-related concept detected via WordNet\")\n",
    "        score += 2\n",
    "\n",
    "    label = \"Strong Fear Appeal\" if score >= 6 else \"Weak/Partial Fear Appeal\" if score >= 4 else \"Not Fear Appeal\"\n",
    "    return label, score, explanations\n"
   ],
   "id": "7cf9149aea813762",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Final method for preprocessing and filtering for all types",
   "id": "7a8603ab85946f5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T16:29:19.482629Z",
     "start_time": "2025-05-15T16:29:15.075842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def classify_schema(row):\n",
    "    question = row[\"question\"]\n",
    "    results = []\n",
    "\n",
    "\n",
    "    cte_label, cte_score, _ = detect_cause_to_effect(question)\n",
    "    if cte_score >= 7:\n",
    "        results.append((\"CauseToEffect\", cte_score))\n",
    "    elif cte_score >= 4:\n",
    "        results.append((\"CauseToEffect\", cte_score))\n",
    "\n",
    "    expert_label, expert_score, _ = detect_expert_opinion(question)\n",
    "    if expert_score >= 6:\n",
    "        results.append((\"ExpertOpinion\", expert_score))\n",
    "    elif expert_score >= 3:\n",
    "        results.append((\"ExpertOpinion\", expert_score))\n",
    "\n",
    "    analogy_label, analogy_score, _ = detect_analogy_question(question)\n",
    "    if analogy_score >= 8:\n",
    "        results.append((\"Analogy\", analogy_score))\n",
    "    elif analogy_score >= 5:\n",
    "        results.append((\"Analogy\", analogy_score))\n",
    "\n",
    "    fear_label, fear_score, _ = detect_fear_appeal_question(question)\n",
    "    if fear_score >= 6:\n",
    "        results.append((\"FearAppeal\", fear_score))\n",
    "    elif fear_score >= 4:\n",
    "        results.append((\"FearAppeal\", fear_score))\n",
    "\n",
    "    results.sort(key=lambda x: -x[1])\n",
    "\n",
    "\n",
    "    schema_labels = [label for label, _ in results]\n",
    "    while len(schema_labels) < 4:\n",
    "        schema_labels.append(\"\")\n",
    "\n",
    "    return pd.Series({\n",
    "        \"schema_1\": schema_labels[0],\n",
    "        \"schema_2\": schema_labels[1],\n",
    "        \"schema_3\": schema_labels[2],\n",
    "        \"schema_4\": schema_labels[3],\n",
    "    })\n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "# TODO: @ CEDRIC  delte and run for all 3 train files (train_chunk1, 2, 3)\n",
    "#filtered_df = filtered_df[:1000]\n",
    "filtered_df[[\"schema_1\", \"schema_2\", \"schema_3\", \"schema_4\"]] = filtered_df.apply(classify_schema, axis=1)\n",
    "filtered_df"
   ],
   "id": "e2a3daba550e0722",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     category                                            context  \\\n",
       "1         0.0  alternate_viewpoints_perspectives: A parallel ...   \n",
       "2         1.0  alternate_viewpoints_perspectives: It would be...   \n",
       "3         2.0  alternate_viewpoints_perspectives: I do not un...   \n",
       "4         3.0  alternate_viewpoints_perspectives: There is a ...   \n",
       "5         4.0  alternate_viewpoints_perspectives: You conside...   \n",
       "..        ...                                                ...   \n",
       "304     303.0  alternate_viewpoints_perspectives: Typically, ...   \n",
       "305     304.0  alternate_viewpoints_perspectives: I want to s...   \n",
       "306     305.0  alternate_viewpoints_perspectives: I'm sorry I...   \n",
       "307     306.0  alternate_viewpoints_perspectives: I get that ...   \n",
       "308     307.0  alternate_viewpoints_perspectives: Not necessa...   \n",
       "\n",
       "                                              question  context_token_len  \\\n",
       "1                 What about nations who have nothing?                126   \n",
       "2           If not, what about this is cringe exactly?                 50   \n",
       "3              What about public surveillance cameras?                 50   \n",
       "4    How about allowing some students to go straigh...                222   \n",
       "5    What else do you imagine is necessary to be co...                144   \n",
       "..                                                 ...                ...   \n",
       "304               Are the highways a little less safe?                 80   \n",
       "305  What about cases where the mother is suicidal ...                 85   \n",
       "306  Would the same things have happened under any ...                 46   \n",
       "307     How about someone from Jamaica with dark skin?                 88   \n",
       "308  And could you dive into more detail about sell...                 76   \n",
       "\n",
       "          schema_1 schema_2 schema_3 schema_4  \n",
       "1                                              \n",
       "2    CauseToEffect                             \n",
       "3                                              \n",
       "4    ExpertOpinion                             \n",
       "5                                              \n",
       "..             ...      ...      ...      ...  \n",
       "304                                            \n",
       "305     FearAppeal                             \n",
       "306                                            \n",
       "307                                            \n",
       "308                                            \n",
       "\n",
       "[300 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>context_token_len</th>\n",
       "      <th>schema_1</th>\n",
       "      <th>schema_2</th>\n",
       "      <th>schema_3</th>\n",
       "      <th>schema_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>alternate_viewpoints_perspectives: A parallel ...</td>\n",
       "      <td>What about nations who have nothing?</td>\n",
       "      <td>126</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>alternate_viewpoints_perspectives: It would be...</td>\n",
       "      <td>If not, what about this is cringe exactly?</td>\n",
       "      <td>50</td>\n",
       "      <td>CauseToEffect</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>alternate_viewpoints_perspectives: I do not un...</td>\n",
       "      <td>What about public surveillance cameras?</td>\n",
       "      <td>50</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>alternate_viewpoints_perspectives: There is a ...</td>\n",
       "      <td>How about allowing some students to go straigh...</td>\n",
       "      <td>222</td>\n",
       "      <td>ExpertOpinion</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>alternate_viewpoints_perspectives: You conside...</td>\n",
       "      <td>What else do you imagine is necessary to be co...</td>\n",
       "      <td>144</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>303.0</td>\n",
       "      <td>alternate_viewpoints_perspectives: Typically, ...</td>\n",
       "      <td>Are the highways a little less safe?</td>\n",
       "      <td>80</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>304.0</td>\n",
       "      <td>alternate_viewpoints_perspectives: I want to s...</td>\n",
       "      <td>What about cases where the mother is suicidal ...</td>\n",
       "      <td>85</td>\n",
       "      <td>FearAppeal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>305.0</td>\n",
       "      <td>alternate_viewpoints_perspectives: I'm sorry I...</td>\n",
       "      <td>Would the same things have happened under any ...</td>\n",
       "      <td>46</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>306.0</td>\n",
       "      <td>alternate_viewpoints_perspectives: I get that ...</td>\n",
       "      <td>How about someone from Jamaica with dark skin?</td>\n",
       "      <td>88</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>307.0</td>\n",
       "      <td>alternate_viewpoints_perspectives: Not necessa...</td>\n",
       "      <td>And could you dive into more detail about sell...</td>\n",
       "      <td>76</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### final check: how many questions per category ?",
   "id": "67c7e6d5f854c8ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T16:30:32.354376Z",
     "start_time": "2025-05-15T16:30:32.347133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_schemas = filtered_df[\"schema_1\"].tolist() + filtered_df[\"schema_2\"].tolist() + filtered_df[\"schema_3\"].tolist() + filtered_df[\"schema_4\"].tolist()\n",
    "all_schemas = [schema for schema in all_schemas if schema]  \n",
    "\n",
    "\n",
    "schema_counts = Counter(all_schemas)\n",
    "\n",
    "schema_summary = pd.DataFrame.from_dict(schema_counts, orient='index', columns=['count'])\n",
    "schema_summary[\"percent\"] = (schema_summary[\"count\"] / len(filtered_df)) * 100\n",
    "schema_summary = schema_summary.sort_values(\"count\", ascending=False)\n",
    "\n",
    "print(\"\\nSchema classification distribution:\")\n",
    "print(schema_summary)\n"
   ],
   "id": "1d52494ad947f855",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schema classification distribution:\n",
      "               count    percent\n",
      "ExpertOpinion     36  12.000000\n",
      "FearAppeal        26   8.666667\n",
      "CauseToEffect     15   5.000000\n",
      "Analogy           12   4.000000\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TODO: check for multiple assignments in final processed training data ",
   "id": "c812e73a5186fa37"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
