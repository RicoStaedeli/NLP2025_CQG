{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RicoStaedeli/NLP2025_CQG/blob/main/Data/processed_data_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata, drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdKk0Lnv6M8B",
        "outputId": "4da79a76-db41-4934-d5be-dcaa1af162b3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_json('/content/drive/MyDrive/HSG/NLP/Project NLP/Data/Final/processed_train_chunk_I.json')\n",
        "df2 = pd.read_json('/content/drive/MyDrive/HSG/NLP/Project NLP/Data/Final/processed_train_chunk_II.json')\n",
        "df3 = pd.read_json('/content/drive/MyDrive/HSG/NLP/Project NLP/Data/Final/processed_train_chunk_III.json')\n",
        "\n",
        "df = pd.concat([df1, df2, df3], ignore_index=True)\n",
        "\n",
        "df.to_json(\"/content/drive/MyDrive/HSG/NLP/Project NLP/Data/Final/processed_train_data.json\")"
      ],
      "metadata": {
        "id": "u--bO0UW6dZx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value_counts = df['is_Critical'].value_counts(dropna=False)\n",
        "print(value_counts)\n",
        "\n",
        "columns = [\"CauseToEffect\", \"ExpertOpinion\", \"Analogy\", \"FearAppeal\"]\n",
        "\n",
        "value_counts_schema = df[columns].apply(pd.Series.value_counts, dropna=False)\n",
        "print(value_counts_schema)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3D854eH4nYv",
        "outputId": "45370560-90be-46ae-e703-ed98ff5bbf16"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is_Critical\n",
            "False    78880\n",
            "True      2105\n",
            "Name: count, dtype: int64\n",
            "   CauseToEffect  ExpertOpinion  Analogy  FearAppeal\n",
            "0          56056        53015.0     4477         571\n",
            "1           1358         1391.0     4178         111\n",
            "2           6594        12925.0    15932       51044\n",
            "3           4660         8721.0    32512       15225\n",
            "4           8200         2882.0    16281       10231\n",
            "5           2133         1929.0     5456        2882\n",
            "6            667          122.0     1662         721\n",
            "7            712            NaN      433         170\n",
            "8            492            NaN       53          28\n",
            "9            113            NaN        1           2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((df['CauseToEffect'] >= 7).sum())\n",
        "print((df['ExpertOpinion'] >= 6).sum())\n",
        "print((df['Analogy'] >= 8).sum())\n",
        "print((df['FearAppeal'] >= 6).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYW5jKC53fyR",
        "outputId": "d5308f04-4747-4aed-cde5-77a57518df2d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1317\n",
            "122\n",
            "54\n",
            "921\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Ein Colab-Abo optimal nutzen",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}