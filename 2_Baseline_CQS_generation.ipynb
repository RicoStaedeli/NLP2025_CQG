{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RicoStaedeli/NLP2025_CQG/blob/main/2_Baseline_CQS_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "d44ba819438d4c7f"
      },
      "cell_type": "markdown",
      "source": [
        "# Baseline Predictions\n",
        "In this file we generate the baseline predictions"
      ],
      "id": "d44ba819438d4c7f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "6yd9jnEIPiXa"
      },
      "id": "6yd9jnEIPiXa"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-28T13:09:03.252191Z",
          "start_time": "2025-04-28T13:09:02.197619Z"
        },
        "id": "56e5bbe87af65278"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import pandas as pd\n",
        "import json\n",
        "import logging\n",
        "import tqdm\n",
        "import re\n",
        "import torch\n",
        "from getpass import getpass\n",
        "from google.colab import userdata, drive\n",
        "import os"
      ],
      "id": "56e5bbe87af65278",
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "o7FZqlh6Wewb",
        "outputId": "9d7b1b94-5c35-4342-fce8-53d458d25da7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "o7FZqlh6Wewb",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token = userdata.get('GITHUB')\n",
        "repo_url = f\"https://{token}@github.com/RicoStaedeli/NLP2025_CQG.git\"\n",
        "\n",
        "!git clone {repo_url}"
      ],
      "metadata": {
        "id": "7tOU4FCdPmop",
        "outputId": "8615b9bf-3f4a-4628-f2f0-5675c4c02a86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7tOU4FCdPmop",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP2025_CQG'...\n",
            "remote: Enumerating objects: 351, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 351 (delta 37), reused 30 (delta 26), pack-reused 301 (from 1)\u001b[K\n",
            "Receiving objects: 100% (351/351), 24.22 MiB | 9.21 MiB/s, done.\n",
            "Resolving deltas: 100% (143/143), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"NLP2025_CQG\")\n",
        "!ls"
      ],
      "metadata": {
        "id": "9jACHoyYTqGU",
        "outputId": "237beda6-eed9-4e7a-cb28-5ab12b0eac86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9jACHoyYTqGU",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1_Preprocessing.ipynb\t\t   Doc\n",
            "2a_Baseline_Evaluation.ipynb\t   Evaluation\n",
            "2_Baseline_CQS_generation.ipynb    LICENSE\n",
            "3a_Finetuned_CQS_generation.ipynb  Logs\n",
            "3b_Finetune_Evaluation.ipynb\t   README.md\n",
            "3_Training.ipynb\t\t   requirements.txt\n",
            "4_Evaluation_Analytics.ipynb\t   Training\n",
            "Data\t\t\t\t   Utils\n",
            "Development\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-28T13:09:03.322602Z",
          "start_time": "2025-04-28T13:09:03.308445Z"
        },
        "id": "c97a513058176f9f",
        "outputId": "a0388464-aaa7-44b8-874e-0982dcaac0e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "#######################   PATH VARIABLES        ################################\n",
        "################################################################################\n",
        "\n",
        "test_dataset_path = \"Data/Processed/test.json\"\n",
        "model_path_llama = \"/content/drive/MyDrive/HSG/NLP/Project NLP/Models/Meta-Llama-3.1-8B-Instruct\"\n",
        "model_path_qwen = \"/content/drive/MyDrive/HSG/NLP/Project NLP/Models/Qwen2.5-7B-Instruct\"\n",
        "results_path = \"Evaluation/Results/\"\n",
        "log_path = \"Logs/2_baseline_predictions.log\"\n",
        "\n",
        "################################################################################\n",
        "#######################   STATIC VARIABLES      ################################\n",
        "################################################################################\n",
        "\n",
        "# Setup logger manually\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "# Create file handler (only if not already added)\n",
        "if not logger.handlers:\n",
        "    fh = logging.FileHandler(log_path)\n",
        "    fh.setLevel(logging.INFO)\n",
        "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "    fh.setFormatter(formatter)\n",
        "    logger.addHandler(fh)\n",
        "\n",
        "# Detect device\n",
        "device = torch.device(\n",
        "    \"mps\" if torch.backends.mps.is_available()\n",
        "    else \"cuda\" if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "\n",
        "# Log the device info\n",
        "logger.info(\"--------  Start with Baseline Predictions  -------------\")\n",
        "logger.info(f'Device selected: {device}')"
      ],
      "id": "c97a513058176f9f",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:--------  Start with Baseline Predictions  -------------\n",
            "INFO:__main__:Device selected: cuda\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "metadata": {
        "id": "4952cbcef0d28c5e"
      },
      "cell_type": "markdown",
      "source": [
        "## Zero Shot prompting\n",
        "In this section we genererate critical questions with different pretrained vanilla models. We use this generated questions as a baseline to compare it against our results. The following models were used to generate the baseline results:\n",
        "- LLama 3.1 8B Instruct\n",
        "- Qwen 2.5 7B Instruct"
      ],
      "id": "4952cbcef0d28c5e"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-28T13:09:03.329368Z",
          "start_time": "2025-04-28T13:09:03.327931Z"
        },
        "id": "bf7c6195fc049988"
      },
      "cell_type": "code",
      "source": [
        "models = [\n",
        "    {\n",
        "        \"name\": \"llama\",\n",
        "        \"model_id\": model_path_llama,\n",
        "        \"output_file\": results_path + \"results_zeroshot_llama_3.1-8B-instruct.json\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"qwen\",\n",
        "        \"model_id\": model_path_qwen,\n",
        "        \"output_file\": results_path + \"results_zeroshot_qwen2.5-7b-instruction.json\",\n",
        "    },\n",
        "]"
      ],
      "id": "bf7c6195fc049988",
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate critical Questions"
      ],
      "metadata": {
        "id": "-4tnhEQlzURL"
      },
      "id": "-4tnhEQlzURL"
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8  # You can adjust this based on your GPU memory\n",
        "\n",
        "def structure_output(whole_text):\n",
        "    cqs_list = whole_text.split('\\n')\n",
        "    final = []\n",
        "    valid = []\n",
        "    not_valid = []\n",
        "    for cq in cqs_list:\n",
        "        if re.match(r'.*\\?(\\\")?( )?(\\([a-zA-Z0-9\\.\\'-\\,\\? ]*\\))?([a-zA-Z \\.,\\\"\\']*)?(\\\")?$', cq):\n",
        "            valid.append(cq)\n",
        "        else:\n",
        "            not_valid.append(cq)\n",
        "\n",
        "    still_not_valid = []\n",
        "    for text in not_valid:\n",
        "        new_cqs = re.split(r'\\?\\\"', text + 'end')\n",
        "        if len(new_cqs) > 1:\n",
        "            for cq in new_cqs[:-1]:\n",
        "                valid.append(cq + '?\"')\n",
        "        else:\n",
        "            still_not_valid.append(text)\n",
        "\n",
        "    for i, cq in enumerate(valid):\n",
        "        occurrence = re.search(r'[A-Z]', cq)\n",
        "        if occurrence:\n",
        "            final.append(cq[occurrence.start():])\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    output = []\n",
        "    if len(final) >= 3:\n",
        "        for i in [0, 1, 2]:\n",
        "            output.append({'cq': final[i]})\n",
        "        return output\n",
        "    else:\n",
        "        return 'Missing CQs'"
      ],
      "metadata": {
        "id": "fwAn93tMywwx"
      },
      "id": "fwAn93tMywwx",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_critical_questions_batch(model, tokenizer, model_name, batch_data):\n",
        "    prompts = [\n",
        "        f\"\"\"Suggest 3 critical questions that should be raised before accepting the arguments in this text:\\n\\n\\\"{item['intervention']}\\\"\\n\\nGive one question per line. Make the questions simple, and do not give any explanation regarding why the question is relevant.\"\"\"\n",
        "        for item in batch_data\n",
        "    ]\n",
        "    inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model.generate(\n",
        "          **inputs,\n",
        "          max_new_tokens=512,\n",
        "          do_sample=True,\n",
        "          temperature=0.6,\n",
        "          top_p=0.9\n",
        "      )\n",
        "\n",
        "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "    del inputs, outputs\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return [\n",
        "        structure_output(decoded[len(prompt):].strip())\n",
        "        for decoded, prompt in zip(decoded_outputs, prompts)\n",
        "    ]"
      ],
      "metadata": {
        "id": "P-t8c-ppywp4"
      },
      "id": "P-t8c-ppywp4",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(test_dataset_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "\n",
        "for model_info in models:\n",
        "    logger.info(f\"Loading model: {model_info['model_id']}\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_info[\"model_id\"])\n",
        "    if tokenizer.pad_token is None:\n",
        "      tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_info[\"model_id\"],\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    output_data = {}\n",
        "    items = list(data.items())\n",
        "\n",
        "    for i in range(0, len(items), batch_size):\n",
        "        batch = items[i:i+batch_size]\n",
        "        batch_ids = [item_id for item_id, _ in batch]\n",
        "        batch_data = [item for _, item in batch]\n",
        "\n",
        "        questions_list = generate_critical_questions_batch(model, tokenizer, model_info[\"name\"], batch_data)\n",
        "\n",
        "        for item_id, questions in zip(batch_ids, questions_list):\n",
        "            if questions == 'Missing CQs':\n",
        "                questions = []\n",
        "\n",
        "            output_data[item_id] = {\n",
        "                \"cqs\": questions\n",
        "            }\n",
        "\n",
        "            logger.info(f\"Generated {item_id}: {questions}\")\n",
        "\n",
        "    with open(model_info[\"output_file\"], 'w') as f:\n",
        "        json.dump(output_data, f, indent=2)\n",
        "\n",
        "    logger.info(f\"Output saved to {model_info['output_file']}\")"
      ],
      "metadata": {
        "id": "mFDwTNeZy6wT",
        "outputId": "81e202e5-8195-467a-a107-23f39b1fea4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492,
          "referenced_widgets": [
            "850a0436d47145b8b5f4ec104601f949",
            "f597c2479f4348d890a7211b8a3b2a26",
            "2effd6d7079a45afa28a6774b3c7aacc",
            "ec5894ffd43f4e45b293a72658005dfd",
            "907a3ae959fd4e3981a4d848c801a438",
            "32d813e875474d18884628635ab73d01",
            "84fcb0827db9413ca7c93af383aa4e6c",
            "0cae747ed78e43aebb544798a0be3b65",
            "3ab4f9800b474f2084959a26bbffbeeb",
            "1c3153fcba9f489c96101868ef56132a",
            "19992afe2eb94309b0f7089a5dbed334",
            "47aec78cd69c4e9c934c58a1cec08bdf",
            "c54bb9319398419a8a6e58c4d25cc69e",
            "d8878ccf271c4c3a887b60a88f589245",
            "368474bb85794b6e989f44a37be975d6",
            "ef86f5d6a0054da88f7cbe5a9b25d0a3",
            "3a965675b1e84e658cfc203e68e6dac8",
            "e4e9074668a2447db486aa74ca595fa6",
            "54f15493b8b34c819ef5185296c770dd",
            "94a02b3aec6c4ac4bbbd7f1b87d0aa68",
            "b69f0851413b44849f7e8677134f1b47",
            "80ffe5c41bdb4983b75053eac8451873"
          ]
        }
      },
      "id": "mFDwTNeZy6wT",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Loading model: /content/drive/MyDrive/HSG/NLP/Project NLP/Models/Meta-Llama-3.1-8B-Instruct\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "850a0436d47145b8b5f4ec104601f949"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "INFO:__main__:Generated CLINTON_199_2: [{'cq': 'What specific actions has Donald Trump taken to demonstrate his dismissal of NATO?'}, {'cq': 'Can the information provided by Muslim communities be verified, or is it potentially biased?'}, {'cq': \"Does the Clinton campaign's emphasis on Muslim communities' potential to provide intelligence reflect a broader strategy of using Islamophobia to gain political support? \"}]\n",
            "INFO:__main__:Generated CLINTON_1_2: [{'cq': 'Clinton proposes to address the stresses faced by working families?'}, {'cq': 'How does Clinton plan to ensure that the wealthy actually pay their fair share?'}, {'cq': 'What are the potential consequences of increasing taxes on corporations and the wealthy? '}]\n",
            "INFO:__main__:Generated CLINTON_21: [{'cq': 'What are the sources of the statistics mentioned in the text?'}, {'cq': 'What are the specific policies proposed by Clinton and Trump that are being compared?'}, {'cq': 'What evidence does Clinton provide to support her claim that climate change is real?'}]\n",
            "INFO:__main__:Generated CLINTON_223_1: [{'cq': \"Is NATO's invocation of Article 5 in response to 9/11 equivalent to a blanket commitment to military action in response to any future terrorist attacks?\"}, {'cq': 'Does the fact that Iran was close to having enough nuclear material to form a bomb when Clinton became Secretary of State necessarily mean that the country was on the verge of becoming a nuclear power?'}, {'cq': \"Is NATO's invocation of Article 5 in response to 9/11 equivalent to a blanket commitment to military action in response to any future terrorist attacks?\"}]\n",
            "INFO:__main__:Generated CLINTON_223_2: [{'cq': 'What specific evidence supports the claim that the sanctions drove Iran to the negotiating table?'}, {'cq': 'Did the sanctions have unintended consequences that undermined their effectiveness?'}, {'cq': \"How did the Obama-Kerry deal impact Iran's nuclear program, and what are the long-term implications of this deal? \"}]\n",
            "INFO:__main__:Generated CLINTON_225: [{'cq': 'What is the definition of \"temperament\" in this context?'}, {'cq': \"Is taunting by others a valid criterion for determining a person's fitness for a leadership position?\"}, {'cq': 'Does being commander-in-chief require a specific temperament that is not possessed by others? '}]\n",
            "INFO:__main__:Generated CLINTON_231: [{'cq': 'What makes the speaker\\'s attitude on nuclear weapons \"cavalier\"?'}, {'cq': 'What evidence supports the claim that nuclear weapons pose the \"number-one threat we face in the world\"?'}, {'cq': \"How does the speaker's claim that terrorists getting their hands on nuclear material is particularly threatening relate to the current situation? \"}]\n",
            "INFO:__main__:Generated CLINTON_235: [{'cq': 'What problem is being referred to?'}, {'cq': 'Who is the intended audience for this statement?'}, {'cq': 'Is the speaker referring to a specific event or situation? '}]\n",
            "INFO:__main__:Output saved to Evaluation/Results/results_zeroshot_llama_3.1-8B-instruct.json\n",
            "INFO:__main__:Loading model: /content/drive/MyDrive/HSG/NLP/Project NLP/Models/Qwen2.5-7B-Instruct\n",
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47aec78cd69c4e9c934c58a1cec08bdf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "INFO:__main__:Generated CLINTON_199_2: [{'cq': 'What specific intelligence benefits does Clinton claim will result from working more closely with allies?'}, {'cq': 'Does Clinton provide evidence for the effectiveness of working with Muslim-majority nations in combating terrorism?'}, {'cq': \"How has Donald Trump's rhetoric specifically impacted Muslim communities and cooperation?\"}]\n",
            "INFO:__main__:Generated CLINTON_1_2: [{'cq': 'What specific policies does Clinton propose for supporting families?  '}, {'cq': 'How does Clinton plan to ensure the wealthy pay their fair share?  '}, {'cq': 'Are there any details on how closing corporate loopholes will fund her proposals?  '}]\n",
            "INFO:__main__:Generated CLINTON_21: [{'cq': 'What evidence supports the claim that returning to previous policies would be detrimental?'}, {'cq': 'Who are these independent experts, and what are their qualifications?'}, {'cq': 'What specific actions or policies does Clinton propose for addressing climate change?'}]\n",
            "INFO:__main__:Generated CLINTON_223_1: [{'cq': \"What specific actions did the speaker take to address Iran's nuclear program?\"}, {'cq': 'Are there any other instances where Article 5 was invoked besides after 9/11?'}, {'cq': \"How effective were sanctions in stopping Iran's nuclear progress?\"}]\n",
            "INFO:__main__:Generated CLINTON_223_2: [{'cq': 'Did Clinton vote for all sanctions against Iran? '}, {'cq': 'Was Clinton involved in a coalition that included Russia and China?'}, {'cq': \"Did Clinton's successor and President Obama achieve a deal without military action? To what extent did Clinton's actions contribute to the deal? \"}]\n",
            "INFO:__main__:Generated CLINTON_225: [{'cq': 'Who defines \"right temperament\"?'}, {'cq': 'What specific incidents are being referred to as \"taunted\"?'}, {'cq': 'How does temperament alone determine fitness for the presidency?'}]\n",
            "INFO:__main__:Generated CLINTON_231: [{'cq': 'Who exactly does \"his\" refer to?'}, {'cq': 'What specific actions demonstrate this \"cavalier attitude\"?'}, {'cq': 'How credible is the claim that terrorists could obtain nuclear materials?'}]\n",
            "INFO:__main__:Generated CLINTON_235: [{'cq': 'Who is \"it\" referring to?'}, {'cq': 'What problem does it describe?'}, {'cq': 'What specific context or evidence supports this claim?'}]\n",
            "INFO:__main__:Output saved to Evaluation/Results/results_zeroshot_qwen2.5-7b-instruction.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Commit & Push"
      ],
      "metadata": {
        "id": "Pqf89mWeUFAl"
      },
      "id": "Pqf89mWeUFAl"
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"Rico Städeli\"\n",
        "!git config --global user.email \"rico@yabriga.ch\""
      ],
      "metadata": {
        "id": "229p1fTlVjw2"
      },
      "id": "229p1fTlVjw2",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "commit_message = \"Generate CQs for Baseline models\"\n",
        "!git add .\n",
        "!git commit -m \"{commit_message}\"\n",
        "!git push"
      ],
      "metadata": {
        "id": "yDYJfL1_UEg-",
        "outputId": "b8463841-0c25-4c1a-9065-f35985488abf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yDYJfL1_UEg-",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 80a31ce] Generate CQs for Baseline models\n",
            " 6 files changed, 212 insertions(+), 8252 deletions(-)\n",
            " delete mode 100644 Evaluation/Results/results_zeroshot_llama_3.1-8B-instruct-finetuned.json\n",
            " delete mode 100644 Evaluation/Results/results_zeroshot_llama_3.1-8B-instruct-finetuned_formated.json\n",
            " rewrite Evaluation/Results/results_zeroshot_llama_3.1-8B-instruct.json (99%)\n",
            " rewrite Evaluation/Results/results_zeroshot_qwen2.5-7b-instruction.json (99%)\n",
            " delete mode 100644 Logs/2_baseline_predictions.log\n",
            " delete mode 100644 Logs/3a_finetuned_cqs_generation.log\n",
            "Enumerating objects: 13, done.\n",
            "Counting objects: 100% (13/13), done.\n",
            "Delta compression using up to 12 threads\n",
            "Compressing objects: 100% (7/7), done.\n",
            "Writing objects: 100% (7/7), 2.60 KiB | 2.60 MiB/s, done.\n",
            "Total 7 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/RicoStaedeli/NLP2025_CQG.git\n",
            "   c92d4b8..80a31ce  main -> main\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "850a0436d47145b8b5f4ec104601f949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f597c2479f4348d890a7211b8a3b2a26",
              "IPY_MODEL_2effd6d7079a45afa28a6774b3c7aacc",
              "IPY_MODEL_ec5894ffd43f4e45b293a72658005dfd"
            ],
            "layout": "IPY_MODEL_907a3ae959fd4e3981a4d848c801a438"
          }
        },
        "f597c2479f4348d890a7211b8a3b2a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32d813e875474d18884628635ab73d01",
            "placeholder": "​",
            "style": "IPY_MODEL_84fcb0827db9413ca7c93af383aa4e6c",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "2effd6d7079a45afa28a6774b3c7aacc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cae747ed78e43aebb544798a0be3b65",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ab4f9800b474f2084959a26bbffbeeb",
            "value": 4
          }
        },
        "ec5894ffd43f4e45b293a72658005dfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c3153fcba9f489c96101868ef56132a",
            "placeholder": "​",
            "style": "IPY_MODEL_19992afe2eb94309b0f7089a5dbed334",
            "value": " 4/4 [00:11&lt;00:00,  2.44s/it]"
          }
        },
        "907a3ae959fd4e3981a4d848c801a438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32d813e875474d18884628635ab73d01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84fcb0827db9413ca7c93af383aa4e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cae747ed78e43aebb544798a0be3b65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ab4f9800b474f2084959a26bbffbeeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c3153fcba9f489c96101868ef56132a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19992afe2eb94309b0f7089a5dbed334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47aec78cd69c4e9c934c58a1cec08bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c54bb9319398419a8a6e58c4d25cc69e",
              "IPY_MODEL_d8878ccf271c4c3a887b60a88f589245",
              "IPY_MODEL_368474bb85794b6e989f44a37be975d6"
            ],
            "layout": "IPY_MODEL_ef86f5d6a0054da88f7cbe5a9b25d0a3"
          }
        },
        "c54bb9319398419a8a6e58c4d25cc69e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a965675b1e84e658cfc203e68e6dac8",
            "placeholder": "​",
            "style": "IPY_MODEL_e4e9074668a2447db486aa74ca595fa6",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d8878ccf271c4c3a887b60a88f589245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54f15493b8b34c819ef5185296c770dd",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94a02b3aec6c4ac4bbbd7f1b87d0aa68",
            "value": 4
          }
        },
        "368474bb85794b6e989f44a37be975d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b69f0851413b44849f7e8677134f1b47",
            "placeholder": "​",
            "style": "IPY_MODEL_80ffe5c41bdb4983b75053eac8451873",
            "value": " 4/4 [04:17&lt;00:00, 64.46s/it]"
          }
        },
        "ef86f5d6a0054da88f7cbe5a9b25d0a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a965675b1e84e658cfc203e68e6dac8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4e9074668a2447db486aa74ca595fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54f15493b8b34c819ef5185296c770dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94a02b3aec6c4ac4bbbd7f1b87d0aa68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b69f0851413b44849f7e8677134f1b47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80ffe5c41bdb4983b75053eac8451873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}