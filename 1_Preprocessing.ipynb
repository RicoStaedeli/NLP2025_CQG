{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing\n",
    "We use the SocratiQ dataset: https://github.com/NUS-IDS/eacl23_soqg/tree/main\n",
    "\n",
    "In this section we preprocess this dataset to generate a corpus for training an LLM to generate accurate critical questions."
   ],
   "id": "2f56613cb80665c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:28:02.286017Z",
     "start_time": "2025-04-29T14:28:01.622282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n"
   ],
   "id": "6ecc1ac6fb7cc1f5",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:28:02.334886Z",
     "start_time": "2025-04-29T14:28:02.332485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "#######################   PATH VARIABLES        ################################\n",
    "################################################################################\n",
    "\n",
    "socraticQ_chunk_1_path = 'Data/Raw/SocraticQ/train_chunk_I.csv'\n",
    "socraticQ_chunk_2_path = 'Data/Raw/SocraticQ/train_chunk_II.csv'\n",
    "socraticQ_chunk_3_path = 'Data/Raw/SocraticQ/train_chunk_III.csv'\n",
    "train_path = 'Data/Processed/SocraticQ/train.csv'\n",
    "val_path = 'Data/Processed/SocraticQ/validation.csv'\n",
    "test_path = 'Data/Processed/SocraticQ/test.csv'\n",
    "\n",
    "################################################################################\n",
    "#######################   STATIC VARIABLES      ################################\n",
    "################################################################################\n",
    "\n",
    "# Setup logger manually\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create file handler (only if not already added)\n",
    "if not logger.handlers:\n",
    "    fh = logging.FileHandler('Logs/data_preprocessing.log')\n",
    "    fh.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    fh.setFormatter(formatter)\n",
    "    logger.addHandler(fh)\n",
    "\n",
    "\n",
    "# Log the device info\n",
    "logger.info(\"--------  Start with Data Preprocessing  -------------\")"
   ],
   "id": "f85787b8d4c6ceef",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T14:28:03.010023Z",
     "start_time": "2025-04-29T14:28:02.344345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the chunks\n",
    "chunk1 = pd.read_csv(socraticQ_chunk_1_path)\n",
    "chunk2 = pd.read_csv(socraticQ_chunk_2_path)\n",
    "chunk3 = pd.read_csv(socraticQ_chunk_3_path)\n",
    "\n",
    "# Concatenate the chunks\n",
    "full_data = pd.concat([chunk1, chunk2, chunk3], ignore_index=True)\n",
    "\n",
    "# Split the data\n",
    "train_data, temp_data = train_test_split(full_data, test_size=0.3, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=2/3, random_state=42)  # 2/3 of 30% is 20%\n",
    "\n",
    "# Save the splits\n",
    "train_data.to_csv(train_path, index=False)\n",
    "val_data.to_csv(val_path, index=False)\n",
    "test_data.to_csv(test_path, index=False)\n",
    "logger.info(f\"Created train, validation and test data sets successfully with random_state=42\")\n",
    "logger.info(\"--------  Finish Data Preprocessing  -------------\")"
   ],
   "id": "8908bee632f59c7b",
   "outputs": [],
   "execution_count": 3
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
