{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing\n",
    "We have a annotated dataset from the paper: https://arxiv.org/pdf/2410.14335\n",
    "\n",
    "In this section we augment and preprocess this dataset to generate a corpus for training an LLM to generate accurate critical questions."
   ],
   "id": "2f56613cb80665c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:05:01.961903Z",
     "start_time": "2025-04-25T08:05:01.958228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import transformers\n",
    "import torch\n",
    "import pandas as pd\n"
   ],
   "id": "6ecc1ac6fb7cc1f5",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:05:01.982523Z",
     "start_time": "2025-04-25T08:05:01.980096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "#######################   PATH VARIABLES        ################################\n",
    "################################################################################\n",
    "\n",
    "output_filtered_path = 'Data/Processed/Filtered/US2016_arguments_filtered.json'\n",
    "raw_input_path = 'Data/Raw/US2016.jsonl'\n",
    "augmented_data_path = 'Data/Processed/Augmented/US2016.json'\n",
    "\n",
    "################################################################################\n",
    "#######################   STATIC VARIABLES      ################################\n",
    "################################################################################\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = \"Models/Meta-Llama-3-8B-Instruct\""
   ],
   "id": "41df56a2b1fac64f",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Filter Data\n",
    "First we have to extract the relevant informations from the not well structured raw dataset. We are only intersted in:\n",
    "- **modified_premises** --> the modified and final used premises\n",
    "- **read_premises** --> the premises for the critical question scheme\n",
    "- **scheme** --> the scheme of the premise\n",
    "- **modified_cqs** --> the generated critical questions"
   ],
   "id": "3ced74ffe92bb0ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:05:02.013055Z",
     "start_time": "2025-04-25T08:05:01.999055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_json(raw_input_path, lines=True)\n",
    "\n",
    "# View the DataFrame\n",
    "print(df.head(5))"
   ],
   "id": "c1c233bbc89c0b3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id       IDS SCHEMES ARGS  \\\n",
      "0     HOLT_0        []      []   []   \n",
      "1     HOLT_2        []      []   []   \n",
      "2  CLINTON_4        []      []   []   \n",
      "3     HOLT_5        []      []   []   \n",
      "4    TRUMP_7  [224122]      []   []   \n",
      "\n",
      "                                        INTERVENTION  \\\n",
      "0  I do n't expect us to cover all the issues of ...   \n",
      "1  thank you\\nIt 's about putting moneyâ€”more mone...   \n",
      "2                        trade is an important issue   \n",
      "3                          would you like to respond   \n",
      "4             We have to renegotiate our trade deals   \n",
      "\n",
      "                                  SENTENCES FULL_ARGS comment  \n",
      "0                                        []        []     NaN  \n",
      "1                                        []        []     NaN  \n",
      "2                                        []        []     NaN  \n",
      "3                                        []        []     NaN  \n",
      "4  [We have to renegotiate our trade deals]        []     NaN  \n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:05:02.038754Z",
     "start_time": "2025-04-25T08:05:02.032521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to extract desired fields from each FULL_ARGS item\n",
    "def extract_argument_info(full_args_list):\n",
    "    extracted = []\n",
    "    for entry in full_args_list:\n",
    "        if isinstance(entry, dict):\n",
    "            extracted.append({\n",
    "                'modified_premises': entry.get('modified_premises', ''),\n",
    "                'read_premises': entry.get('read_premises', ''),\n",
    "                'scheme': entry.get('scheme', ''),\n",
    "                'modified_cqs': entry.get('modified_cqs', '')\n",
    "            })\n",
    "    return extracted\n",
    "\n",
    "# Flatten FULL_ARGS from all rows\n",
    "all_args_data = []\n",
    "for full_args in df['FULL_ARGS']:\n",
    "    all_args_data.extend(extract_argument_info(full_args))\n",
    "\n",
    "# Convert to DataFrame\n",
    "args_df = pd.DataFrame(all_args_data)\n",
    "\n",
    "# Save to JSON\n",
    "\n",
    "args_df.to_json(output_filtered_path, orient='records', indent=2)\n",
    "\n",
    "output_filtered_path"
   ],
   "id": "5564f705674db0f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data/Processed/Filtered/US2016_arguments_filtered.json'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:05:02.076880Z",
     "start_time": "2025-04-25T08:05:02.068942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_filtered = pd.read_json(output_filtered_path)\n",
    "df_filtered.info()"
   ],
   "id": "c502bd762df0a693",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 408 entries, 0 to 407\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   modified_premises  408 non-null    object\n",
      " 1   read_premises      408 non-null    object\n",
      " 2   scheme             408 non-null    object\n",
      " 3   modified_cqs       408 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 12.9+ KB\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Augment the existing dataset\n",
    "We try to augment the dataset by rephrasing the generated questions and also the use premises.\n",
    "For that we use *Meta-Llama-3-8B-Instruct*."
   ],
   "id": "488cec00de6ffdc0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:05:02.101479Z",
     "start_time": "2025-04-25T08:05:02.099315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_answer(pipe, terminator, input_text):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant to rephrase given text. But you always keep in mind that the meaning must not change.\"},\n",
    "        {\"role\": \"user\", \"content\": input_text},\n",
    "    ]\n",
    "\n",
    "    prompt = pipe.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "    )\n",
    "    outputs = pipe(\n",
    "        prompt,\n",
    "        max_new_tokens=256,\n",
    "        eos_token_id=terminator,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "\n",
    "    return outputs[0][\"generated_text\"][len(prompt):]"
   ],
   "id": "92b64a2ab224120c",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:05:14.065028Z",
     "start_time": "2025-04-25T08:05:02.116609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_filtered = pd.read_json(output_filtered_path)\n",
    "system_prompt = \"Please rephrase the following input text and give a direct answer without something like Here is a rephrased version of the text: \"\n",
    "\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_path,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "\n",
    "for premise in df_filtered['modified_premises']:\n",
    "    input_text = system_prompt + premise\n",
    "    rephrased = generate_answer(pipeline, terminators, input_text)\n",
    "    print(\"Input text: \", input_text)\n",
    "    print(\"Rephrased text: \", rephrased)\n",
    "    print(\"-----------\")\n",
    "    break\n",
    "\n"
   ],
   "id": "87d2486748783132",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d67a8237c224c099fed4a9444951744"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:  Please rephrase the following input text and give a direct answer without something like Here is a rephrased version of the text: \n",
      "we 've created a movement is true in this situation.\n",
      "we 've created a movement is often a sign of situations in which Clinton and others, politicians, should have been doing this for years is true.\n",
      "Clinton and others, politicians, should have been doing this for years might be true in this situation.\n",
      "Rephrased text:  The creation of a movement in this situation is a long-overdue indication that Clinton and other politicians should have taken action years ago.\n",
      "-----------\n"
     ]
    }
   ],
   "execution_count": 29
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
