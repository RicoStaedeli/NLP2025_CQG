{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install textstat"],"metadata":{"id":"IJ1bQaNGMh_9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, GPT2LMHeadModel, GPT2Tokenizer\n","from sentence_transformers import SentenceTransformer, util\n","import spacy\n","import textstat\n","\n","# Load models and tools\n","bert_model = SentenceTransformer('all-MiniLM-L6-v2')\n","gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Input text and generated question\n","source_text = \"The French Revolution was a period of far-reaching social and political upheaval in France and its colonies.\"\n","generated_question = \"How did the French Revolution influence modern political ideologies?\"\n","\n","# 1. Relevance: Semantic similarity\n","source_emb = bert_model.encode(source_text, convert_to_tensor=True)\n","question_emb = bert_model.encode(generated_question, convert_to_tensor=True)\n","relevance_score = util.cos_sim(source_emb, question_emb).item()\n","\n","# 2. Clarity\n","def calculate_perplexity(text):\n","    inputs = gpt2_tokenizer(text, return_tensors=\"pt\")\n","    with torch.no_grad():\n","        outputs = gpt2_model(**inputs, labels=inputs[\"input_ids\"])\n","    return torch.exp(outputs.loss).item()\n","\n","def grammar_errors(text):\n","    doc = nlp(text)\n","    # Simple grammar heuristic: count tokens with dependency 'dep'\n","    return sum(1 for token in doc if token.dep_ == \"dep\")\n","\n","perplexity = calculate_perplexity(generated_question)\n","grammar_issue_count = grammar_errors(generated_question)\n","readability_score = textstat.flesch_reading_ease(generated_question)\n","\n","# 3. Depth: Semantic distance (proxy for abstraction)\n","depth_score = 1 - relevance_score\n","\n","# 4. Insightfulness: Heuristic\n","abstract_keywords = [\"impact\", \"influence\", \"significance\", \"consequences\", \"assumption\", \"implication\"]\n","insightfulness_score = depth_score\n","if any(word in generated_question.lower() for word in abstract_keywords):\n","    insightfulness_score += 1\n","\n","# Results\n","print(\"\\n--- Critical Question Evaluation ---\")\n","print(f\"Question: {generated_question}\\n\")\n","print(f\"Relevance Score (0–1): {relevance_score:.3f}\")\n","print(f\"Perplexity (lower = better): {perplexity:.2f}\")\n","print(f\"Grammar Issue Count (lower = better): {grammar_issue_count}\")\n","print(f\"Readability Score (Flesch, higher = easier): {readability_score:.2f}\")\n","print(f\"Depth Score (0–1): {depth_score:.3f}\")\n","print(f\"Insightfulness Score (0–2): {insightfulness_score:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":378},"id":"54-LM-Hm8re7","executionInfo":{"status":"error","timestamp":1746106084354,"user_tz":-120,"elapsed":35627,"user":{"displayName":"Rico Städeli","userId":"17684829322768155794"}},"outputId":"8f90b436-9132-4a42-ef1c-ad0431188880"},"execution_count":2,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'textstat'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-2d4d8ddfad2e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtextstat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load models and tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'textstat'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","source":["# Evaluation of Baseline predictions\n","In this notebook we evaluate the results of our baseline predictions. For the baseline the following pretrained models are used:\n","- Llama 3.1-8B-Instruct\n","- Qwen2.5 7B Instruct"],"metadata":{"id":"PObhsFPu8vX9"}},{"cell_type":"markdown","source":["## Libraries and Installation"],"metadata":{"id":"D__-Jqvu9OTN"}},{"cell_type":"code","source":["# !pip install sentence-transformers evaluate scikit-learn"],"metadata":{"collapsed":true,"id":"3tGZA-MT3UHc"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# !pip install git+https://github.com/google-research/bleurt.git"],"metadata":{"id":"5XCIN_HbI8Cy"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["!pip install evaluate"],"metadata":{"id":"1D56ttFi9r1S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import logging\n","import os\n","import json\n","import torch\n","import numpy as np\n","from collections import Counter\n","from sentence_transformers import SentenceTransformer\n","from sklearn.metrics.pairwise import cosine_similarity\n","from evaluate import load"],"metadata":{"id":"6vq84kLn26Lj"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hOHUHsXO5G_n","executionInfo":{"status":"ok","timestamp":1746105032367,"user_tz":-120,"elapsed":15262,"user":{"displayName":"Rico Städeli","userId":"17684829322768155794"}},"outputId":"6520c660-2520-40e7-cf6d-fbb4f8906912"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"execution_count":1},{"cell_type":"markdown","source":["## Static Variables and Paths"],"metadata":{"id":"BherrjmE9FYA"}},{"cell_type":"code","source":["################################################################################\n","#######################   STATIC VARIABLES      ################################\n","################################################################################\n","\n","EVALUATION_NAME = \"Evaluation_Llama_3.1_8B_Instruct\"\n","\n","sim_threshold = 0.6 # recommened 0.6 -0.75 [0,1]\n","bleurt_threshold = 0.2 # recommened 0.2 - 0.4 [-1,1]\n","\n","sentence_transformer_model = \"stsb-mpnet-base-v2\"\n","\n","################################################################################\n","#######################   PATH VARIABLES        ################################\n","################################################################################\n","\n","log_dir = f\"/content/drive/MyDrive/HSG/NLP/Project NLP/Evaluation/{EVALUATION_NAME}/\"\n","os.makedirs(log_dir, exist_ok=True)\n","\n","base_file_path = '/content/drive/MyDrive/HSG/NLP/Project NLP/Data/sample.json'\n","generated_cqs_path = '/content/drive/MyDrive/HSG/NLP/Project NLP/Data/results_zeroshot_llama_3.1-8B-instruct-finetuned_formated.json'\n","evaluation_result_path = \"\"\n","\n","# Setup logger manually\n","logger = logging.getLogger(__name__)\n","logger.setLevel(logging.INFO)\n","\n","# Create file handler (only if not already added)\n","if not logger.handlers:\n","    fh = logging.FileHandler(f'{log_dir}{EVALUATION_NAME}.log')\n","    fh.setLevel(logging.INFO)\n","    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n","    fh.setFormatter(formatter)\n","    logger.addHandler(fh)\n"],"metadata":{"id":"9z9B4oqE9N6A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Detect device\n","device = torch.device(\n","    \"mps\" if torch.backends.mps.is_available()\n","    else \"cuda\" if torch.cuda.is_available()\n","    else \"cpu\"\n",")\n","\n","logger.info(f\"--------  Start with evaluation for {EVALUATION_NAME}  -------------\")\n","logger.info(f'Device selected: {device}')\n","logger.info(f'Similarity threshold: {sim_threshold}')\n","logger.info(f'Bleurt threshold: {bleurt_threshold}')\n","logger.info(f'Sentence transformer model: {sentence_transformer_model}')"],"metadata":{"id":"yP_VPE2v3ABd"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["## Evaluation"],"metadata":{"id":"reeGN8Dm9YZ4"}},{"cell_type":"code","source":["# === Load model ===\n","sim_model = SentenceTransformer(sentence_transformer_model)\n","bleurt_model = load(\"bleurt\", module_type=\"metric\")"],"metadata":{"id":"EShdGaTn3D_6"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# === Load data ===\n","with open(base_file_path) as f:\n","    reference = json.load(f)\n","\n","with open(generated_cqs_path) as f:\n","    new = json.load(f)"],"metadata":{"id":"GwNz7_GD3F17"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# === Evaluate ===\n","predicted_labels = []\n","punctuations = []\n","\n","\n","for instance in new.keys():\n","    sim_punctuation = 0\n","    bleurt_punctuation = 0\n","    reference_set = [ref['cq'] for ref in reference[instance]['cqs']]\n","\n","    if new[instance]['cqs'] != 'Missing CQs':\n","        cqs_check = [cq['cq'] for cq in new[instance]['cqs']]\n","        if len(cqs_check) != len(set(cqs_check)):\n","            logger.warning('There are repeated CQs in ' + instance)\n","\n","        for i, line in enumerate(new[instance]['cqs']):\n","\n","            sim_winner = None\n","            sim_sentence_embedding = sim_model.encode(line['cq'])\n","            sim_reference_embedding = sim_model.encode(reference_set)\n","            sims = sim_model.similarity(sim_sentence_embedding, sim_reference_embedding).tolist()[0]\n","\n","            sim_winner = np.argmax(sims)\n","            sims_max_score = sims[sim_winner]\n","\n","            if sims_max_score > sim_threshold:\n","                simlabel = reference[instance]['cqs'][sim_winner]['label']\n","                if simlabel == 'Useful':\n","                    sim_punctuation += 1/3\n","            else:\n","                label = 'not_able_to_evaluate'\n","            new[instance]['cqs'][i]['sim_label'] = simlabel\n","            new[instance]['cqs'][i]['sim_score'] = sims_max_score\n","\n","\n","            bleuert_winner = None\n","            bleurt_results = bleurt_model.compute(predictions=[line['cq']] * len(reference_set), references=reference_set)\n","            bleurt = bleurt_results['scores']\n","\n","            bleuert_winner = np.argmax(bleurt)\n","            bleurt_max_score = bleurt[bleuert_winner]\n","\n","            if bleurt_max_score > bleurt_threshold:\n","                bleurt_label = reference[instance]['cqs'][bleuert_winner]['label']\n","                if bleurt_label == 'Useful':\n","                    bleurt_punctuation += 1/3\n","            else:\n","                bleurt_label = 'not_able_to_evaluate'\n","            new[instance]['cqs'][i]['bleurt_label'] = bleurt_label\n","            new[instance]['cqs'][i]['bleurt_score'] = bleurt_max_score\n","\n","            predicted_labels.append((simlabel, bleurt_label))\n","\n","    else:\n","        predicted_labels.extend([('not_able_to_evaluate', 'not_able_to_evaluate'), ('not_able_to_evaluate', 'not_able_to_evaluate'), ('not_able_to_evaluate', 'not_able_to_evaluate')])\n","\n","    new[instance]['sim_score'] = sim_punctuation\n","    new[instance]['bleurt_score'] = bleurt_punctuation\n","    punctuations.append((sim_punctuation, bleurt_punctuation))\n","    logger.info(f'{instance} score (based on similarity): {sim_punctuation:.2f}/1.00 score (based on bleurt): {bleurt_punctuation:.2f}/1.00')"],"metadata":{"collapsed":true,"id":"kJOvVHwgfIcs"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# === Summary ===\n","logger.info('------ Summary Metrics ------')\n","logger.info(f'Distribution of labels: {Counter(predicted_labels)}')\n","logger.info(f'Distribution of punctuation: {Counter(punctuations)}')\n","total_sim, total_bleurt = 0.0, 0.0\n","for sim, bleurt in punctuations:\n","    total_sim += sim\n","    total_bleurt += bleurt\n","\n","avg_sim = total_sim / len(punctuations) if punctuations else 0.0\n","avg_bleurt = total_bleurt / len(punctuations) if punctuations else 0.0\n","\n","logger.info(f'Overall sim punctuation: {avg_sim:.4f}')\n","logger.info(f'Overall bleurt punctuation: {avg_bleurt:.4f}')\n","\n","# === Save updated results with labels ===\n","output_path = generated_cqs_path[:-5] + f'_eval.json'\n","with open(output_path, 'w') as o:\n","    json.dump(new, o, indent=4)\n","logger.info(f\"Saved labeled output to {output_path}\")"],"metadata":{"id":"-9gmGu_x3IIS"},"outputs":[],"execution_count":null}]}